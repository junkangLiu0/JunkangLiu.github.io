
---
layout: home
title: åˆ˜ä¿Šåº· | Junkang Liu
subtitle: åšå£«ç ”ç©¶ç”Ÿ @ å¤©æ´¥å¤§å­¦ <br> ç ”ç©¶æ–¹å‘ï¼šè”é‚¦å­¦ä¹  | ä¼˜åŒ–ç®—æ³• | å¤§æ¨¡å‹é«˜æ•ˆå¾®è°ƒ
---

<div style="text-align: center;">
  <img src="/fig1.jpg" alt="avatar" width="160" style="border-radius: 50%; box-shadow: 0 0 10px rgba(0,0,0,0.15); margin-bottom: 20px;">

  
  <div style="margin: 10px 0;">
    <a class="btn btn--primary" href="/assets/cv/cv_liu_junkang.pdf" target="_blank">ğŸ“„ ä¸‹è½½ç®€å† / Download CV</a>
    <a class="btn btn--inverse" href="mailto:junkangliukk@gmail.com">âœ‰ï¸ è”ç³»æˆ‘ / Email</a>
  </div>

  <div style="font-size: 1.2rem;">
    <a href="https://github.com/junkangliu" target="_blank">ğŸŒ GitHub</a> |
    <a href="https://scholar.google.com" target="_blank">ğŸ“š Google Scholar</a>
  </div>
</div>

---

ğŸ“ **ç®€ä»‹ / About Me**

æˆ‘ç›®å‰æ˜¯ **å¤©æ´¥å¤§å­¦** è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šåšå£«ç ”ç©¶ç”Ÿï¼Œç¡•å£«æ¯•ä¸šäº **è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢**ã€‚ç ”ç©¶å…´è¶£æ¶µç›–ï¼š

- âš™ï¸ è”é‚¦å­¦ä¹ ï¼ˆFederated Learningï¼‰
- ğŸ” å·®åˆ†éšç§ä¼˜åŒ–ä¸æ³›åŒ–ç†è®º
- ğŸ§  å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFT, LoRA, BitFit ç­‰ï¼‰
- ğŸ“‰ éå‡¸ä¼˜åŒ–ç†è®º

æ›¾ä»¥ç¬¬ä¸€ä½œè€…èº«ä»½åœ¨ **ICMLã€ACM MM ç­‰ CCF A ç±»ä¼šè®®** å‘è¡¨å¤šç¯‡è®ºæ–‡ã€‚

---

ğŸ“« **è”ç³»æ–¹å¼ / Contact**

- ğŸ“§ é‚®ç®±ï¼šjunkangliukk@gmail.com  
- ğŸŒ GitHubï¼š[@junkangliu](https://github.com/junkangliu)  
- ğŸ“š Google Scholarï¼š[é“¾æ¥](https://scholar.google.com)
  


ğŸ“° **æœ€æ–°åŠ¨æ€ / News**
- âœ‰ï¸ [2025] å‘ AAAI æŠ•ç¨¿æœ€æ–°æˆæœã€ŠFedAdamW: Convergence and Generalization in FLã€‹
- âœ‰ï¸ [2025] å‘ TIFS æŠ•ç¨¿æœ€æ–°æˆæœã€ŠFinding Globally Flat Minima for DP Federated Learningã€‹
- âœ‰ï¸ [2025] å‘ TIFS æŠ•ç¨¿æœ€æ–°æˆæœã€ŠFinding Globally Flat Minima for DP Federated Learningã€‹
- âœ… [2025] ACM MM è®ºæ–‡ã€ŠGeneralized Federated Learning via Sharpness Aware Minimization with Nesterov Extrapolationã€‹è¢«æ¥æ”¶ï¼
- âœ… [2025] ICML è®ºæ–‡ã€ŠImproving Generalization in Federated Learning with Heterogeneous Data via Momentum-Based SWAã€‹è¢«æ¥æ”¶ï¼
- ğŸ† [2024] è£è·ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘
- âœ… [2025] ACM MM è®ºæ–‡ã€ŠFedBCGD: Communication-Efficient Accelerated Block Coordinate Gradient Descent for Federated Learningã€‹è¢«æ¥æ”¶ï¼
- âœ‰ï¸ [2023] å‘ AAAI ä¸ TPAMI æŠ•ç¨¿æœ€æ–°æˆæœ

---

ğŸ’¼ **ç ”ç©¶æ–¹å‘ / Research Interests**

- <strong>Federated Learning</strong>: å¤šå®¢æˆ·ç«¯åˆ†å¸ƒå¼å»ºæ¨¡ã€é«˜æ•ˆé€šä¿¡ä¼˜åŒ–
- <strong>Efficient Fine-tuning</strong>: å‚æ•°å¾®è°ƒæ–¹æ³•ï¼ˆLoRA, BitFit, Adapterï¼‰
- <strong>Privacy-Preserving ML</strong>: å·®åˆ†éšç§æœºåˆ¶ä¸ä¼˜åŒ–ç­–ç•¥
- <strong>Optimization Theory</strong>: åŠ¨é‡æ–¹æ³•ã€æ³›åŒ–è¯¯å·®ã€éå‡¸ç†è®º

### å·²å‘è¡¨è®ºæ–‡

1. **FedBCGD: Communication-Efficient Accelerated Block Coordinate Gradient Descent for Federated Learning**  
   ğŸ“Œ ACM MM, 2024 Â· CCF A Â· ç¬¬ä¸€ä½œè€…

2. **Improving Generalization in Federated Learning with Heterogeneous Data via Momentum-Based SWA**  
   ğŸ“Œ ICML, 2025 Â· CCF A Â· ç¬¬ä¸€ä½œè€…

3. **Generalized Federated Learning via Sharpness Aware Minimization with Nesterov Extrapolation**  
   ğŸ“Œ ACM MM, 2025 Â· CCF A Â· ç¬¬ä¸€ä½œè€…

4. **Temporal Dynamic Technology Convergence Prediction Based on DySAT Model**  
   ğŸ“Œ æƒ…æŠ¥ç§‘å­¦, 2023 Â· ä¸­æ–‡æ ¸å¿ƒ Â· ç¬¬äºŒä½œè€…ï¼ˆå­¦ç”Ÿä¸€ä½œï¼‰

---
### å·²æŠ•æˆ–åœ¨å®¡è®ºæ–‡

1. **Dynamic Differentially Private Online ADMM Algorithms**  
   æŠ•ç¨¿è‡³ IEEE TIFS Â· CCF A Â· SCI ä¸€åŒºï¼ˆå°ä¿®ï¼‰  
   ğŸ‘¤ å­¦ç”Ÿä¸€ä½œï¼Œç¬¬äºŒä½œè€…

2. **Tight High-Probability Bounds for Nonconvex Heavy-Tailed Scenario**  
   æŠ•ç¨¿è‡³ NeurIPS Â· CCF A  
   ğŸ‘¤ å­¦ç”ŸäºŒä½œ

3. **Finding Globally Flat Minima for DP Federated Learning**  
   æŠ•ç¨¿è‡³ IEEE TIFS Â· CCF A Â· SCI ä¸€åŒº  
   ğŸ‘¤ ç¬¬ä¸€ä½œè€…

4. **IGFL: Local & Global Consistency in Federated Learning**  
   æŠ•ç¨¿è‡³ IEEE TPAMI Â· CCF A Â· SCI ä¸€åŒº  
   ğŸ‘¤ ç¬¬ä¸€ä½œè€…

5. **FedAdamW: Convergence and Generalization in FL**  
   æŠ•ç¨¿è‡³ AAAI Â· CCF A  
   ğŸ‘¤ ç¬¬ä¸€ä½œè€…

6. **DP Federated Learning with Laplacian**  
   æŠ•ç¨¿è‡³ IEEE TKDE Â· CCF A Â· SCI ä¸€åŒº  
   ğŸ‘¤ å­¦ç”Ÿä¸€ä½œ


---
### æ•™è‚²ç»å†

- ğŸ“š **åšå£«ï¼ˆ2025.06~ï¼‰**  
  å¤©æ´¥å¤§å­¦ Â· è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯

- ğŸ“ **ç¡•å£«ï¼ˆ2022.09 ~ 2025.06ï¼‰**  
  è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ Â· äººå·¥æ™ºèƒ½å­¦é™¢ Â· è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯

- ğŸ“ **æœ¬ç§‘ï¼ˆ2018.09 ~ 2022.06ï¼‰**  
  é’å²›å¤§å­¦ Â· æ•°å­¦ä¸åº”ç”¨æ•°å­¦


---

### ç§‘ç ”é¡¹ç›®

**å›½è‡ªç„¶é¢ä¸Šé¡¹ç›®ï¼š** å¤§è§„æ¨¡æœºå™¨å­¦ä¹ åŠ¨é‡åŠ é€Ÿæ–¹æ³•çš„ç†è®ºç ”ç©¶ä¸åº”ç”¨  
â± å‚ä¸æ—¶é—´ï¼š2022.09 ~ 2024.12  
ğŸ’¼ èŒè´£ï¼šå‚ä¸ç®—æ³•è®¾è®¡ã€å®éªŒæ­å»ºã€è®ºæ–‡æ’°å†™

### è·å¾—è£èª‰

- ğŸ– 2024 å¹´ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘  
- ğŸ– 2020 å¹´æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘  
- ğŸ– é’å²›å¤§å­¦å¹´åº¦åä½³ä¼˜ç§€å­¦ç”Ÿ  
- ğŸ¥ˆ å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦ç«èµ› å…¨å›½äºŒç­‰å¥–  
- ğŸ¥ˆ å…¨å›½å¤§å­¦ç”Ÿå»ºæ¨¡ç«èµ› å…¨å›½äºŒç­‰å¥–  
- ğŸ¥‡ ç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ› Må¥–



å¦‚å¯¹æˆ‘çš„ç ”ç©¶æ–¹å‘æ„Ÿå…´è¶£ï¼Œæ¬¢è¿é‚®ä»¶è”ç³»æˆ–å­¦æœ¯åˆä½œï¼
